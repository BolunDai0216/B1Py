{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple Position controller\n",
    "This example uses the Vicon as pose measurement sensor and uses a simple proportional controller to control the position of the robot. The output of the controller is desired linear and angular velocities represented in the body coordinate frame and is fed to the B1's onboard locomotion controller. Following shows the control architecture:\n",
    "\n",
    "Add the image\n",
    "\n",
    "Add the math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare the Robot and Connect to it\n",
    "As explained in the [high-level interfacing tutorial](unitree_locomotion_controller_interface.ipynb), turn the robot on and put it in walking mode. Then run the following cell to connect to it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UDP Initialized. socketfd: 55   Port: 8080\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Error] Bind client ip&port failed: Address already in use\n"
     ]
    }
   ],
   "source": [
    "from B1Py.interfaces import B1HighLevelReal\n",
    "import time\n",
    "robot = B1HighLevelReal()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then test the interface to make sure you can indeed command the robot:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(100):\n",
    "    time.sleep(0.01)\n",
    "    robot.setCommand(0.0,0,0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Establish Interface to the Vicon\n",
    "Then, we need to establish a connection to the Vicon system to read the robot's pose. As explained in the [Vicon through ROS tutorial](vicon_through_ros.ipynb), run the `vicon_bridge` and the following cell to instantiate an interface for reading the pose of the marker attached to the robot in the world coordinate frame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: cannot load logging configuration file, logging is disabled\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unable to register with master node [http://localhost:11311/]: master may not be running yet. Will keep trying.\n"
     ]
    }
   ],
   "source": [
    "from B1Py.utils import addROSPath\n",
    "# Add ROS to the ptyhon path. \n",
    "addROS2Path('/opt/ros/noetic') \n",
    "from B1Py.ros_bridges import initRosNode, ROSTFListener\n",
    "# Initialize the ROS node for the current python process\n",
    "initRosNode('b1py_node')\n",
    "# Create a TF listener object that listens to the transform of robot vicon mareker with respect to the world world_T_marker\n",
    "pose_sensor = ROSTFListener('vicon/world', 'vicon/b1_body_whole_1/b1_body_whole_1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the connection was a success, you should be able to read the measured transformation matrix (marker frame with respect to the robot body frame) as below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.99305802, -0.11701313,  0.01198734,  0.05164038],\n",
       "       [ 0.11732368,  0.99264891, -0.02972015,  0.69296006],\n",
       "       [-0.00842157,  0.03092023,  0.99948638,  0.78387855],\n",
       "       [ 0.        ,  0.        ,  0.        ,  1.        ]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pose_sensor.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, the pose that you read with this sensor is for the marker and not the body frame. To control the robot properly, we need to apply a transformation to convert it to the desired transformation. As explained in the [Calibration Results Aggregation and `B1Params` Class](), we get the pose of the marker frame with respect to the body frame (robot IMU frame) during the calibration procedure. \n",
    "\n",
    "*Modify this section after finalizing the calibration procedure*\n",
    "\n",
    "Let's read the calibration parameters and use it get the pose of the robot body in vicon world frame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from B1Py.calibration import parseVico2GtParams\n",
    "body_T_marker = parseVico2GtParams('notebooks/sample_params/vicon2gt/unitree_imu.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For sanity check, use the `ROSTFPublisher` class provided as part of B1Py to visualize the robot body frame in vicon world frame using the Rviz tool. Simply run the following cell while the Rviz is on with origin set to the `vicon/world`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from B1Py.ros_bridges import ROSTFPublisher\n",
    "import time\n",
    "tf_pub = ROSTFPublisher('vicon/world', 'vicon/dog')\n",
    "\n",
    "for i in range(300):\n",
    "    world_T_marker = pose_sensor.T\n",
    "    T = world_T_marker @ np.linalg.inv(body_T_marker)\n",
    "    tf_pub.publish(T)\n",
    "    time.sleep(0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Controlling the Robot\n",
    "Now that we can command the robot and read its pose in the world, let's close the loop and control its position. To keep things clean and reusable, we do this using a class that instantiates a thread for continuously reading the pose, computing the control command, and sending it to the robot. \n",
    "\n",
    "We have also added generic APIs to simply command the robot in both relative (go to a pose with respect to where you are right now) and absolute (go to a particular pose with respect to a home pose defined by that last call to `setCurrentAsHome` method). For future applications, we have also added a user callback option that is given the computed control command and returns a modified version of it. This callback may be used to implement safety filters using CBFQP techniques. \n",
    "\n",
    "The class is documented so go through them and then instantiate it to start commanding the robot:\n",
    "\n",
    "***Note:*** Pressing any of the `L1`, `L2`, `L3`, or `L4` is interpreted as emergency stop and terminates the position controller. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import threading\n",
    "import pypose as pp\n",
    "class PositionController():\n",
    "    \"\"\"\n",
    "    Class responsible for the position Control of the robot through the \n",
    "    high-level interface (robot takes velocity and yaw angular rate commands).\n",
    "\n",
    "    Attributes:\n",
    "        loop_freq (int): The frequency of the control loop.\n",
    "        robot (object): An instance of `B1HighLevelReal` class\n",
    "        pose_sensor (object): An instance of `ROSTFListener` or similar classes.\n",
    "        sensor_T_body (numpy.ndarray): 4x4 Transformation representing the pose of sensor with respect to body frame.\n",
    "        Kp_yaw (float): Proportional gain for yaw control.\n",
    "        Ki_yaw (float): Integral gain for yaw control.\n",
    "        Kp_pos (float): Proportional gain for position control.\n",
    "        Ki_pos (float): Integral gain for position control.\n",
    "        user_callback (func): User-defined callback function executed before sending the control command to the robot.\n",
    "    \"\"\"\n",
    "    def __init__(self, \n",
    "                robot, \n",
    "                pose_sensor, \n",
    "                body_T_sensor, \n",
    "                loop_freq=100, \n",
    "                Kp_yaw = 0.8,\n",
    "                Ki_yaw = 0.02,\n",
    "                Kp_pos = 0.8,\n",
    "                Ki_pos = 0.02,\n",
    "                user_callback = None):\n",
    "        \"\"\"\n",
    "        Initialize a new PositionController.\n",
    "\n",
    "        Parameters:\n",
    "            robot (object): An instance of the `B1HighLevelReal` class or similar interfaces.\n",
    "            pose_sensor (object): An instance of the `ROSTFListener` class or similar sensors.\n",
    "            body_T_sensor (numpy.ndarray): 4x4 Transformation representing the pose of sensor with respect to body frame.\n",
    "            loop_freq (int, optional): Frequency of the control loop. Defaults to 100.\n",
    "            Kp_yaw (float, optional): Proportional gain for yaw control. Defaults to 0.8.\n",
    "            Ki_yaw (float, optional): Integral gain for yaw control. Defaults to 0.02.\n",
    "            Kp_pos (float, optional): Proportional gain for position control. Defaults to 0.8.\n",
    "            Ki_pos (float, optional): Integral gain for position control. Defaults to 0.02.\n",
    "            user_callback (func, optional): User-defined callback function. Defaults to None.\n",
    "        \"\"\"\n",
    "        self.loop_freq=loop_freq\n",
    "        self.robot = robot\n",
    "        self.pose_sensor = pose_sensor\n",
    "        self.sensor_T_body = np.linalg.inv(body_T_sensor)\n",
    "        self.running = True\n",
    "        self.jogging = False\n",
    "        self.Kp_yaw = Kp_yaw\n",
    "        self.Ki_yaw = Ki_yaw\n",
    "        self.Kp_pos = Kp_pos\n",
    "        self.Ki_pos = Ki_pos\n",
    "        self.body_height = 0\n",
    "        self.step_height = 0\n",
    "        self.user_callback = user_callback\n",
    "        self.setCurrentAsHome()\n",
    "        self.control_thread = threading.Thread(target = self.controlLoop)\n",
    "        self.control_thread.start()\n",
    "        \n",
    "    \n",
    "    def getAbsolutePose(self):\n",
    "        \"\"\"\n",
    "        Get the absolute pose of the robot as reported by the sensor with respect to the \n",
    "        perception/Vicon world frame.\n",
    "\n",
    "        Returns:\n",
    "            numpy.ndarray: The absolute 4x4 pose matrix.\n",
    "        \"\"\"\n",
    "        T = self.pose_sensor.T @ self.sensor_T_body\n",
    "        return T\n",
    "\n",
    "    def getRelativePose(self):\n",
    "        \"\"\"\n",
    "        Get the relative pose of the robot with respect to the home set during\n",
    "        the instantiation of the class or latest execution of the setCurrentAsHome method.\n",
    "\n",
    "        Returns:\n",
    "            numpy.ndarray: The relative 4x4 pose matrix.\n",
    "        \"\"\"\n",
    "        return self.T0_inv@self.getAbsolutePose()\n",
    "    \n",
    "    def setCurrentAsHome(self):\n",
    "        \"\"\"\n",
    "        Set the current position and orientation as the home (reference) point.\n",
    "        \"\"\"\n",
    "        self.T0_inv = np.linalg.inv(self.getAbsolutePose())\n",
    "        self.p_des = np.array([0.,0.])\n",
    "        self.yaw_des = 0.0\n",
    "\n",
    "    def getState(self):\n",
    "        \"\"\"\n",
    "        Retrieve the current state of the robot.\n",
    "\n",
    "        Returns:\n",
    "            tuple: Current x, y, and yaw of the robot.\n",
    "        \"\"\"\n",
    "        T = self.getRelativePose() \n",
    "        yaw = self.pose2Yaw(T)\n",
    "        x, y = T[0,-1], T[1,-1]\n",
    "        return x, y, yaw\n",
    "\n",
    "    def pose2Yaw(self, T):\n",
    "        \"\"\"\n",
    "        Convert a transformation matrix to a yaw angle.\n",
    "\n",
    "        Parameters:\n",
    "            T (numpy.ndarray): Transformation matrix.\n",
    "\n",
    "        Returns:\n",
    "            float: Yaw angle in radians.\n",
    "        \"\"\"\n",
    "        return pp.euler(pp.mat2SE3(T))[2].item()\n",
    "\n",
    "    def go2Relative(self, x, y, heading):\n",
    "        \"\"\"\n",
    "        Command the robot to move to a relative pose with respect\n",
    "        to the current pose of the robot.\n",
    "\n",
    "        Parameters:\n",
    "            x (float): Relative x-coordinate.\n",
    "            y (float): Relative y-coordinate.\n",
    "            heading (float): Relative heading in radians.\n",
    "        \"\"\"\n",
    "        self.setCurrentAsHome()\n",
    "        self.p_des = np.array([x, y])\n",
    "        self.yaw_des = heading\n",
    "\n",
    "    def go2Absolute(self, x, y, heading):\n",
    "        \"\"\"\n",
    "        Command the robot to move to an absolute pose with respect to\n",
    "        the home pose defined during the instantiation of the class or \n",
    "        latest call to the `setCurrentAsHome` method.\n",
    "\n",
    "        Parameters:\n",
    "            x (float): Absolute x-coordinate.\n",
    "            y (float): Absolute y-coordinate.\n",
    "            heading (float): Absolute heading in radians.\n",
    "        \"\"\"\n",
    "        self.p_des = np.array([x, y])\n",
    "        self.yaw_des = heading\n",
    "    \n",
    "    def perf_controller(self):\n",
    "        \"\"\"\n",
    "        Perform the control computations to get the command to be sent to the robot.\n",
    "\n",
    "        Returns:\n",
    "            tuple: Control commands vx, vy, and omega in robot body frame.\n",
    "        \"\"\"\n",
    "        x, y, yaw = self.getState()\n",
    "        # yaw controller\n",
    "        R = pp.euler2SO3([0,0,yaw]).matrix()\n",
    "        e_yaw = self.yaw_des - yaw\n",
    "        yaw_cmd = self.Kp_yaw * e_yaw\n",
    "        # translational controller\n",
    "        e_x = self.p_des[0] - x\n",
    "        e_y = self.p_des[1] - y\n",
    "        x_cmd = self.Kp_pos*e_x\n",
    "        y_cmd = self.Kp_pos*e_y\n",
    "        # Rotate the command vector into the body frame\n",
    "        cmd_in_world = np.array([x_cmd, y_cmd, 0]).reshape(3,1)\n",
    "        cmd_in_body  = (R.T@cmd_in_world)[0:2] \n",
    "        u_perf = cmd_in_body[0].item(), cmd_in_body[1].item(), yaw_cmd\n",
    "        return u_perf\n",
    "\n",
    "    def startJogging(self):\n",
    "        \"\"\"\n",
    "        Activate the control, the robot starts jogging.\n",
    "        \"\"\"\n",
    "        self.jogging = True\n",
    "    \n",
    "    def stopJogging(self):\n",
    "        \"\"\"\n",
    "        Deactivate the control, the robot stops jogging.\n",
    "        \"\"\"\n",
    "        self.jogging = False\n",
    "\n",
    "    def close(self):\n",
    "        \"\"\"\n",
    "        Stop the control loop and terminate the thread.\n",
    "        \"\"\"\n",
    "        self.running = False\n",
    "        self.control_thread.join()\n",
    "\n",
    "    def setBodyHeightOffset(self, h):\n",
    "        \"\"\"\n",
    "        Set the height offset for the robot's body \n",
    "        with respect to the nominal height.\n",
    "\n",
    "        Parameters:\n",
    "            h (float): Height offset.\n",
    "        \"\"\"\n",
    "        self.body_height = h\n",
    "\n",
    "    def setStepHeightOffset(self, h):\n",
    "        \"\"\"\n",
    "        Set the swing foot height offset.\n",
    "\n",
    "        Parameters:\n",
    "            h (float): Step height offset.\n",
    "        \"\"\"\n",
    "        self.step_height = h\n",
    "\n",
    "    def controlLoop(self):\n",
    "        \"\"\"\n",
    "        Control loop that continuously updates the robot's state and issues control commands.\n",
    "        \"\"\"\n",
    "        while self.running:\n",
    "            emergency_stop = self.robot.state.wirelessRemote[2]\n",
    "            if emergency_stop:\n",
    "                print(\"User pressed the E-Stop switch, terminating the controller ...\")\n",
    "                self.running = False\n",
    "            if self.jogging:\n",
    "                cmd = self.perf_controller()\n",
    "                # In case we need a CBFQP filter\n",
    "                if self.user_callback is not None:\n",
    "                    cmd = self.user_callback(cmd)\n",
    "                #clip the max speed to some safe limits\n",
    "                cmd = np.clip(np.array(cmd), -1,1)\n",
    "                self.robot.setCommand(cmd[0], cmd[1], cmd[2], bodyHeight = self.body_height, \n",
    "                                                              footRaiseHeight = self.step_height,  \n",
    "                                                              mode = 2)\n",
    "            else:\n",
    "                self.robot.setCommand(0, 0, 0, bodyHeight = self.body_height, \n",
    "                                               footRaiseHeight = self.step_height,  \n",
    "                                               mode = 0)\n",
    "            time.sleep(1/self.loop_freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User pressed the E-Stop switch, terminating the controller ...\n"
     ]
    }
   ],
   "source": [
    "position_controller = PositionController(robot, pose_sensor, body_T_marker)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now activate the controller by starting the jogging mode:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "position_controller.startJogging()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's first ask the robot to go forward for $0.3m$ and achieve a $0.3$ radian heading:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "position_controller.go2Relative(0.3, 0.0, 0.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's got back to where we were:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "position_controller.go2Relative(-0.3, 0.0, -0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can do the same thing with through the absolute API:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Go to x=0.3m, y=0m, and yaw=0.3rad\n",
    "position_controller.go2Absolute(0.3,0,0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Return to where we where: to x=0m, y=0m, and yaw=0rad\n",
    "position_controller.go2Absolute(0,0,0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that we can also change the step and body height as we go:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "position_controller.setBodyHeightOffset(-0.05)\n",
    "position_controller.setStepHeightOffset(0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After playing enough with the robot, stop jogging and terminate the controller:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "position_controller.stopJogging()\n",
    "position_controller.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, sit the robot down and turn it off as described in the [Python Interface with the Unitree's Controller (High-Level) Tutorial](unitree_locomotion_controller_interface.ipynb)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyenv38",
   "language": "python",
   "name": "pyenv38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
